
<!DOCTYPE html>
<body>
    <header>
        <h1>Mixing Data-driven and Geometric Models for Satellite Docking Port State Estimation using an RGB or Event Camera</h1>
         </header>
    <main>
        <section id="authors">
            <h2>Authors</h2>
            <p>
                Cedric Le Gentil</a><sup>1</sup>, Jack Naylor</a><sup>2</sup>, Nuwan Munasinghe</a><sup>1</sup>, Jasprabhjit Mehami</a><sup>2</sup>, Benny Dai</a><sup>1</sup>, Mikhail Asavkin</a><sup>3</sup>, Donald G. Dansereau</a><sup>2</sup>, Teresa Vidal-Calleja</a><sup>1</sup>
            </p>
            <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>University of Technology Sydney<br><sup>2</sup>The University of Sydney<br><sup>3</sup>ANT61</span>
            </div>
            </header>
            <main>
                <section id="abstract">
                    <h2>Abstract</h2>
                    <p>
                        In-orbit automated servicing is a promising path towards lowering the cost of satellite operations and reducing the amount of orbital debris. For this purpose, we present a pipeline for automated satellite docking port detection and state estimation using monocular vision data from standard RGB sensing or an event camera. Rather than taking snapshots of the environment, an event camera has independent pixels that asynchronously respond to light changes, offering advantages such as high dynamic range, low power consumption and latency. This work focuses on satellite-agnostic operations (only a geometric knowledge of the actual port is required) using the recently released Lockheed Martin Mission Augmentation Port (LM-MAP) as the target. By leveraging shallow data-driven techniques to preprocess the incoming data to highlight the LM-MAP’s reflective navigational aids and then using basic geometric models for state estimation, we present a lightweight and data-efficient pipeline that can be used independently with either RGB or event cameras.
                    </p>
                </section>
                <section id="video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/SuDh-xhnaVY?si=4WK1LZ36q-Pxav6M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                </section>
            <section id="links">
            <h2>Links</h2>
            <p><a href="https://github.com/UTS-RI/rgb_event_docking_port" target="_blank"></a></p>
            <p><a href="https://uts-ri.github.io/rgb_event_docking_port/" target="_blank">Dataset and Project Page</a></p>
        </section>
    </main>

 <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      @inproceedings{legentilicra2025,
        title={Mixing Data-driven and Geometric Models for Satellite Docking Port State Estimation using an RGB or Event Camera}, 
        author={Cedric Le Gentil and Jack Naylor and Nuwan Munasinghe and Jasprabhjit Mehami and Benny Dai and Mikhail Asavkin and Donald G. Dansereau and Teresa Vidal-Calleja},
        year={2025},
        booktitle={IEEE International Conference on Robotics and Automation},
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->
</body>
</html>
